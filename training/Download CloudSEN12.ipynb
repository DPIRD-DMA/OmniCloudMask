{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tacoreader\n",
    "import rasterio as rio\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook downloads the CloudSEN12 dataset both the 509 and the 2k images and labels, only the data with pixel level labels, \n",
    "About 30GB of data, 3-4 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = Path(\"/media/nick/4TB Working 7/Datasets/CloudSEN12\")\n",
    "dst_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_data_extent = True  # remove padding from 512 images to 509\n",
    "num_threads = 2  # number of threads to use for parallel processing\n",
    "include_2k_images = False  # include 2k images in the dataset\n",
    "bands = [4, 3, 9]  # Red(B04), Green(B03), NIR(B08A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bands(\n",
    "    dataset,\n",
    "    id: int,\n",
    "    output_dir: Path,\n",
    "    true_shape: int,\n",
    "    file_name: str,\n",
    "    processing_level: str,\n",
    ") -> None:\n",
    "    output_path = output_dir / f\"{file_name}_image_{processing_level}.tif\"\n",
    "    if output_path.exists():\n",
    "        return\n",
    "    img_path = dataset.read(id).read(0)\n",
    "    with rio.open(img_path) as src:\n",
    "        bands_data = src.read(\n",
    "            bands,\n",
    "        )\n",
    "        profile = src.profile\n",
    "        profile.update(count=len(bands))\n",
    "        if clip_data_extent:\n",
    "            bands_data = bands_data[:, :true_shape, :true_shape]\n",
    "            profile.update(width=true_shape, height=true_shape)\n",
    "\n",
    "    with rio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(bands_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label(\n",
    "    dataset,\n",
    "    id: int,\n",
    "    output_dir: Path,\n",
    "    true_shape: int,\n",
    "    file_name: str,\n",
    ") -> None:\n",
    "    output_path = output_dir / f\"{file_name}_label.tif\"\n",
    "    if output_path.exists():\n",
    "        return\n",
    "    label_path = dataset.read(id).read(1)\n",
    "    with rio.open(label_path) as lbl_src:\n",
    "        labels_data = lbl_src.read()\n",
    "\n",
    "        label_profile = lbl_src.profile\n",
    "        label_profile[\"compress\"] = \"lzw\"\n",
    "        if clip_data_extent:\n",
    "            labels_data = labels_data[:, :true_shape, :true_shape]\n",
    "            label_profile.update(width=true_shape, height=true_shape)\n",
    "\n",
    "    with rio.open(output_path, \"w\", **label_profile) as lbl_dst:\n",
    "        lbl_dst.write(labels_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(\n",
    "    output_dir: Path,\n",
    "    id: int,\n",
    "    dataset,\n",
    "    file_name: str,\n",
    "    true_shape: int,\n",
    "    processing_level: str,\n",
    "    label: bool,\n",
    "    retry_count: int = 0,\n",
    "):\n",
    "    try:\n",
    "        save_bands(dataset, id, output_dir, true_shape, file_name, processing_level)\n",
    "\n",
    "        if label:\n",
    "            save_label(dataset, id, output_dir, true_shape, file_name)\n",
    "        return\n",
    "\n",
    "    except Exception as e:\n",
    "        retry_count += 1\n",
    "\n",
    "        if retry_count > 5:\n",
    "            print(f\"Failed to process ID {id} after multiple retries. Skipping.\")\n",
    "            return\n",
    "\n",
    "        sleep_time = retry_count * 4\n",
    "        print(f\"Retrying {id} in {sleep_time} seconds... {e}\")\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "        download(\n",
    "            output_dir,\n",
    "            id,\n",
    "            dataset,\n",
    "            file_name,\n",
    "            true_shape,\n",
    "            processing_level,\n",
    "            label,\n",
    "            retry_count=retry_count,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(\n",
    "    output_dir: Path, processing_level: str, label=True, include_2k_images=False\n",
    "):\n",
    "    dataset = tacoreader.load(f\"tacofoundation:cloudsen12-{processing_level}\")\n",
    "    args = []\n",
    "    if include_2k_images:\n",
    "        image_sizes = [509, 2000]\n",
    "    else:\n",
    "        image_sizes = [509]\n",
    "    for id, (_, row) in enumerate(dataset.iterrows()):\n",
    "        true_shape = int(row[\"real_proj_shape\"])\n",
    "\n",
    "        if row[\"label_type\"] == \"high\" and true_shape in image_sizes:\n",
    "            file_name = (\n",
    "                f\"{row['tortilla:id']}_{row['tortilla:data_split']}_{true_shape}\"\n",
    "            )\n",
    "\n",
    "            args.append(\n",
    "                (\n",
    "                    output_dir,\n",
    "                    id,\n",
    "                    dataset,\n",
    "                    file_name,\n",
    "                    true_shape,\n",
    "                    processing_level,\n",
    "                    label,\n",
    "                )\n",
    "            )\n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        list(tqdm(pool.imap(lambda x: download(*x), args), total=len(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7133985e4074c03976831fea0a2566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_dataset(dst_dir, processing_level=\"l1c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f00f44529746e592b65f4d250bbbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_dataset(dst_dir, processing_level=\"l2a\", label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocm-trainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
